{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evolution Strategies\n",
    "======="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory\n",
    "**Evolutionary Strategies (ES)** is a metaheuristic optimization technique to approximate the global optimum of a function.\n",
    "\n",
    "## Definition\n",
    "**ES** belong to the family of evolutionary algorithms. Evolutionary algorithms are inspired by the biological theory of evolution. To understand the algorithm, lets give a small recap on the evolutionary process\n",
    "> Evolutionary process is the adaptation process of organisms overtime, to achieve survival. This process is based on the rule \"survival of the fittest\" and achieved through natural selection. Natural selection believes that individuals with traits beneficial to their survival can live through generations and pass down the good characteristics to the next generation.\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"https://lilianweng.github.io/posts/2019-09-05-evolution-strategies/EA-illustration.png\" width=\"600\"/></div>\n",
    "\n",
    "By analogy, evolutionary strategies algorithm try to model the process of natural selection, in attempt to achieve this inheritance process of good traits in individuals through the generations. Where in biological systems this process is a way of adaptation, in context of search problem it could be used as an anchor to the optima. So to model the process in context of optimization problems so key concepts needs to be imported\n",
    "- Population\n",
    "- Offsprings\n",
    "- Generation\n",
    "- Mutation\n",
    "\n",
    "These concepts will control how evolutionary strategies algorithm explore the search space. In a sense the algorithm will have a greedy temptation of go to the nearest optima, due to the mechanics of natural selection process \"i.e. always favouring solutions with good traits\". However, introduction of mutation parameter will fight back this temptation by providing worst \"un-optimal\" solutions in the neighborhood, so the algorithm do not stuck in a local optima. So the general behavior of the algorithm will be to pass down good traits to new solutions, while introducing solutions with good/bad mutations to escape local optima.\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"../Resources/Evolution Strategies - Generation.png\" width=\"600\"/></div>\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "\n",
    "Evolution strategies use problem repersentation of the solution candicates and it search the search space based on that. So the search space is the same as the search space of the problem.\n",
    "Unlike other evolutionary algorithms, it does not use any form of crossover; instead, modification of candidate solutions is limited to mutation operators. In this way, Evolution Strategies may be thought of as a type of parallel stochastic hill climbing.\n",
    "\n",
    "## Examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Callable\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation and offsprings sizes respectively\n",
    "lam = 20\n",
    "mu = 10\n",
    "\n",
    "# mutation control parameters\n",
    "mean = 0\n",
    "SD = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "```mermaid\n",
    "    flowchart TB\n",
    "\n",
    "        x_0(Start with starting \\nsolution x_0) --> Loop\n",
    "        x_0 --> population(Initial population)\n",
    "        population --> Loop\n",
    "        \n",
    "        subgraph Loop\n",
    "            direction LR\n",
    "\n",
    "            offsprings(Selection of population <br> offsprings) --> condition{Is the best offspring cost better <br>than current cost?}\n",
    "            condition --> |True| move(Move to offspring)\n",
    "            condition --> |False| stay(Stay where you are)\n",
    "            \n",
    "            move --> Mutation\n",
    "            stay --> Mutation\n",
    "\n",
    "            subgraph Mutation\n",
    "                direction TB\n",
    "            \n",
    "                children(Produce children <br>from offsprings using <br> normal distribution) --> add(Create new  population set <br>from offsprings children)\n",
    "            end\n",
    "\n",
    "            Mutation --> update(Update population)\n",
    "\n",
    "        end\n",
    "\n",
    "        Loop --> return(Return current solution)\n",
    "\n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ES(fitness_func: Callable, generate_children: Callable, lam: int, mu: int, x_0: float, mean: float = 0, SD: float = 1.5, generations: int = int(5e2)) -> tuple[float, list, int]:\n",
    "    '''\n",
    "    Evolution strategies algorithm to approximated the global optimum of a given continuous cost function\n",
    "\n",
    "    Args:\n",
    "        fitness_func: Cost function, for this algorithm it should be 1D continues mathematical expression, function should return float\n",
    "        generate_children: Generate solution neighbors sampled from normal distribution. function should return np array \n",
    "        lam: Size of population\n",
    "        mu: Size of offsprings\n",
    "        x_0: Search start value\n",
    "        mean: Mutation parameter. Defaults to 0.\n",
    "        SD: Mutation parameter. Defaults to 1.5.\n",
    "        generations: Maximum number of generations. Defaults to int(5e2).\n",
    "\n",
    "    Returns:\n",
    "        The optimal x value of the cost function, the number of accepted samples during search, and the search\n",
    "        history record.\n",
    "    '''\n",
    "\n",
    "    # parameters\n",
    "    population = generate_children(x_0, size=lam, mean=mean, SD=SD)\n",
    "    number_children = int(lam/mu)\n",
    "    accepted_samples = 0\n",
    "\n",
    "    # algorithm data \n",
    "    generations_population = [population]\n",
    "    mutation_parameters = [[mean, SD]]\n",
    "    fitness = [fitness_func(x_0)]\n",
    "    x = [x_0]\n",
    "\n",
    "\n",
    "    for _ in range(generations-1):\n",
    "        \n",
    "        # offsprings selection\n",
    "        population_fitness = np.array([fitness_func(neighbor) for neighbor in population])\n",
    "        offsprings = population[ population_fitness.argsort()[:mu] ]\n",
    "\n",
    "\n",
    "        # check the merit of best offspring \n",
    "        best_offspring = offsprings[0]\n",
    "\n",
    "        ## accept it if better fitness\n",
    "        if fitness_func(best_offspring) < fitness_func(x[-1]):\n",
    "            x.append(best_offspring)\n",
    "            fitness.append(fitness_func(best_offspring))\n",
    "            generations_population.append(population)\n",
    "            accepted_samples+=1\n",
    "\n",
    "        ## reject it \"keep current best\"\n",
    "        else:\n",
    "            x.append(x[-1])\n",
    "            fitness.append(fitness_func(x[-1]))\n",
    "            generations_population.append(population)\n",
    "\n",
    "\n",
    "        # produce new population \"with mutation\"\n",
    "        offsprings_children = []\n",
    "        for offspring in offsprings:\n",
    "            children = generate_children(offspring, size=number_children, mean=mean, SD=SD)\n",
    "            offsprings_children.extend(children)\n",
    "       \n",
    "        population = np.array(offsprings_children)\n",
    "        mutation_parameters.append([mean, SD])\n",
    "\n",
    "    x_optimal, history = x[-1], pd.DataFrame({\"fitness\": fitness, \"x\": x, \"population\": generations_population, \"mutation\": mutation_parameters})\n",
    "\n",
    "\n",
    "    return x_optimal, accepted_samples, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Visualization & Behaver Analysis\n",
    "In this section we will illustrate the results and behavior of evolution strategies by solving the following problem\n",
    "- Find global optima in a mathematical function\n",
    "\n",
    "We will illustrate the results of the algorithm in two means:\n",
    "- gif Plot: Search process of algorithm to illustrate how populations fitness evolve through generations to reach optimal fitness\n",
    "- Samples Plot: Search samples taken and show the suggested global optima\n",
    "- Parameters Tracking Plot: ES parameters tracking, illustrate mutation parameters behavior though generations, tacking of x value and cost to shows how algorithm explore search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function and neighborhood definition\n",
    "def cost_func(x: float) -> float:\n",
    "    '''\n",
    "    The cost is calculated use a mathematical expression \"i.e. the mathematical function to be optimized\"\n",
    "    '''\n",
    "    return 30*np.sin(x) + x**2\n",
    "\n",
    "def get_neighborhood(x: float, size: int, mean: float = 0, SD: float = 1.5) -> np.array:\n",
    "    '''\n",
    "    The neighborhood around x is defined as the sampled values from a normal distribution centred on x. This means that the bonds \n",
    "    of the neighborhood of x is infinite. Note that x is excluded from this list.\n",
    "    '''\n",
    "    return x + np.random.normal(loc=mean, scale=SD, size=size)\n",
    "\n",
    "# starting value search\n",
    "x_0 = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_optimal, accepted_samples, history = ES(fitness_func=cost_func,\n",
    "                                          generate_children=get_neighborhood,\n",
    "                                          lam=20,\n",
    "                                          mu=10,\n",
    "                                          x_0=x_0,\n",
    "                                          generations=20\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "# fine domain and range limits\n",
    "xx = np.linspace(min(map(min, history[\"population\"]))-4, max(map(max, history[\"population\"]))+4, num=100)\n",
    "y_lim = [np.min(cost_func(xx))-0.2*np.ptp(cost_func(xx)), np.max(cost_func(xx))+0.2*np.ptp(cost_func(xx))]\n",
    "\n",
    "# evolution strategies sampling animation \n",
    "## statics components\n",
    "main_function,      = ax.plot(xx, cost_func(xx), \"k\")\n",
    "sample_x_ticks,     = ax.plot([history[\"x\"][0]], [y_lim[0]], \"r|\", clip_on=False, zorder=100)\n",
    "sample_line,        = ax.plot([], [], \"r--\")\n",
    "sample_point,       = ax.plot([], [], \"ro\")\n",
    "population_point,   = ax.plot([], [], \"r2\", label=\"Population\")\n",
    "generation_count,   = ax.plot([], [], \"k>\", label=\"Generation = \"+\"{:.2f}\".format(1))\n",
    "\n",
    "## decorations\n",
    "ax.set(xlabel=\"x\", ylabel=\"f(x)\", ylim=y_lim, title=\"Evolution Strategies Generations\")\n",
    "legend = ax.legend()\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "def animate(frame: int) -> tuple:\n",
    "\n",
    "    ## animated components\n",
    "    sample_line.set_data([history[\"x\"][frame], history[\"x\"][frame]], [y_lim[0], cost_func(history[\"x\"][frame])])\n",
    "    sample_point.set_data([history[\"x\"][frame]], [cost_func(history[\"x\"][frame])])\n",
    "    population_point.set_data([history[\"population\"][frame]], [cost_func(history[\"population\"][frame])])\n",
    "    sample_x_ticks.set_data([history[\"x\"][:frame]], [y_lim[0]])\n",
    "    legend.get_texts()[1].set_text(\"Generation = \"+\"{}\".format(frame+1))\n",
    "\n",
    "    return sample_line, population_point, sample_point, sample_x_ticks\n",
    "\n",
    "ani = FuncAnimation(fig, animate, frames=len(history[\"x\"]), blit=True, interval=30)\n",
    "\n",
    "ani.save('../Resources/Evolution Strategies-Result.gif', writer=PillowWriter(fps=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"../Resources/Evolution Strategies-Result.gif\" width=\"500\"/></div>  \n",
    "<em>If the gif is not updated, please reopen the notebook.</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplot_mosaic([['upper left', 'upper right'],\n",
    "                              ['upper left',       'right'],\n",
    "                              ['upper left', 'lower right']],\n",
    "                             figsize=(17,7), gridspec_kw={'width_ratios': [1, 1.4]})\n",
    "\n",
    "\n",
    "# evolution strategies sampling plot\n",
    "ax['upper left'].plot(xx, cost_func(xx), \"k\", label=\"Optimized function\")\n",
    "ax['upper left'].plot(history[\"x\"][0], cost_func(history[\"x\"][0]), \"yo\", label=\"Starting point\", zorder=4)\n",
    "ax['upper left'].plot(history[\"x\"], cost_func(history[\"x\"]), \"o\", label=f\"Successful generations = {accepted_samples}\")\n",
    "ax['upper left'].plot(x_optimal, cost_func(x_optimal), \"ro\", label=\"Optimal point\")\n",
    "ax['upper left'].set(xlabel=\"x\", ylabel=\"f(x)\", title=\"Evolution Strategies Generations\")\n",
    "ax['upper left'].grid(True)\n",
    "ax['upper left'].legend()\n",
    "\n",
    "# mutation parameters tracking\n",
    "ax['upper right'].plot(history[\"mutation\"].apply(lambda x:x[0]), \"tab:red\", label=\"mean\")\n",
    "ax['upper right'].plot(history[\"mutation\"].apply(lambda x:x[1]), \"r\", label=\"SD\")\n",
    "ax['upper right'].set(ylabel=\"mutation\", title=\"Parameters Tracking\")\n",
    "ax['upper right'].xaxis.set_ticklabels([])\n",
    "ax['upper right'].grid(True)\n",
    "ax['upper right'].legend()\n",
    "\n",
    "# x value tracking\n",
    "ax['right'].plot(history[\"x\"], label=\"x\")\n",
    "ax['right'].xaxis.set_ticklabels([])\n",
    "ax['right'].set(ylabel=\"x\")\n",
    "ax['right'].grid(True)\n",
    "ax['right'].legend()\n",
    "\n",
    "# cost value tracking\n",
    "ax['lower right'].plot(history[\"fitness\"], label=\"fitness\")\n",
    "ax['lower right'].set(xlabel=\"Iterations\", ylabel=\"fitness\")\n",
    "ax['lower right'].grid(True)\n",
    "ax['lower right'].legend()\n",
    "\n",
    "# summary\n",
    "summary = [\n",
    "    (\"optimal x\", x_optimal),\n",
    "    (\"fitness at optimal x\", cost_func(x_optimal)),\n",
    "    (\"total search generations\", f'{len(history[\"x\"])} samples'),\n",
    "    (\"accepted generations\", f'{accepted_samples} samples'),\n",
    "    (\"rejected generations\", f'{len(history[\"x\"]) - accepted_samples} samples')\n",
    "    ]\n",
    "\n",
    "df = pd.DataFrame(data=summary, columns=[\"Property\", \"Value\"])\n",
    "\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.14)\n",
    "plt.show()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
