{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory\n",
    "\n",
    "## Definition\n",
    "\n",
    "\n",
    "## Examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "from sympy.abc import x\n",
    "from typing import Callable\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = x**3           # use sp. methods only \"i.e sp.cos()\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD(f: Callable, x_0: float, step: float, TOL: float = 1e-5, maxiter: int = int(1e5)) -> tuple[float, float, int]:\n",
    "    '''\n",
    "    _summary_\n",
    "\n",
    "    Args:\n",
    "        f: _description_\n",
    "        x_0: _description_\n",
    "        step: _description_\n",
    "        TOL: _description_. Defaults to 1e-5.\n",
    "\n",
    "    Returns:\n",
    "        _description_\n",
    "    '''\n",
    "    \n",
    "    # function derivative\n",
    "    f_prime = sp.lambdify('x', sp.diff(f))\n",
    "\n",
    "\n",
    "    x = np.zeros(maxiter)\n",
    "    x[0] = x_0\n",
    "\n",
    "    for i in range(maxiter):\n",
    "        \n",
    "        x[i+1] = x[i] - step*f_prime(x[i])\n",
    "        \n",
    "        # convergence condition\n",
    "        if abs(x[i] - x[i+1]) < TOL:\n",
    "            break\n",
    "\n",
    "        # handel divergence & not enough iterations\n",
    "        if abs(x[i] - x[i+1]) > 1e5:\n",
    "            warnings.warn(f\"GD diverged where delta x = {abs(x[i] - x[i+1])}, choose smaller step size\")\n",
    "            break\n",
    "        elif i+1==maxiter-1:\n",
    "            warnings.warn(f\"GD need more iterations steps = {i+1}, increase maxiter argument\")\n",
    "            break\n",
    "    \n",
    "    steps = i+1\n",
    "    x_min, history = x[i+1], x[:steps+1]\n",
    "\n",
    "    return x_min, history, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3w/hd5h2k7x1vj43929dpnp39p40000gn/T/ipykernel_46423/3695181737.py:33: UserWarning: GD diverged where delta x = 128841.23245239253, choose smaller step size\n",
      "  warnings.warn(f\"GD diverged where delta x = {abs(x[i] - x[i+1])}, choose smaller step size\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.50000000e+00, -1.06250000e+01, -2.47695312e+02, -1.29088928e+05])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_min, history, steps = GD(f=func, x_0=2.5, step=0.7)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
